{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "800f91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855ee752",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb372040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataco_data_filtered.csv')\n",
    "#1. remove data after 2017\n",
    "df['Order date (DateOrders)'] = pd.to_datetime(df['Order date (DateOrders)'])\n",
    "df = df.loc[df['Order date (DateOrders)']< pd.to_datetime('2015-03-01')]\n",
    "\n",
    "#2.add weekday dummy\n",
    "df['weekday']=np.where((df['Order date (DateOrders)'].dt.dayofweek) <5, 0,1)\n",
    "\n",
    "#3.agreggate date \n",
    "number = df.groupby(\"Order date (DateOrders)\")['Order Item Quantity'].count().reset_index()\n",
    "number = number.rename(columns={\"Order Item Quantity\": \"Total Volume\"})\n",
    "df = pd.merge(df,number,left_on='Order date (DateOrders)',right_on='Order date (DateOrders)')\n",
    "\n",
    "#sample 10,000 from our data\n",
    "# df = df.sample(n=10000)\n",
    "\n",
    "df = df.drop(['Order date (DateOrders)'],axis =1)\n",
    "def reduce_class(col,df,n):\n",
    "    count_df = df.groupby(col).size().reset_index().rename(columns={0 : 'count'})\n",
    "    sort_df = count_df.sort_values('count',ascending = False)\n",
    "    top_n = list(sort_df[col][:n])\n",
    "    reduced_col = df[col].apply(lambda x: x if x in top_n else 'Other')\n",
    "    return reduced_col\n",
    "\n",
    "df['Category Name'] = reduce_class('Category Name',df,10)\n",
    "df['Store City'] = reduce_class('Store City',df,10)\n",
    "df['Customer State'] = reduce_class('Customer State',df,10)\n",
    "# cat_count = df.groupby(\"Category Name\")[['Category Name']].count().rename(columns={'Category Name' : 'count'}).reset_index()\n",
    "# sorted_cats = cat_count.sort_values(\"count\", ascending = False)\n",
    "# top10_cats = sorted_cats['Category Name'][:10].to_list()\n",
    "# df['Category Name'] = df['Category Name'].apply(lambda x: x if x in top10_cats else 'Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a27e0",
   "metadata": {},
   "source": [
    "### classification data + classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35bea639",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_columns = ['Order State','Order City','Customer Id','Product Name','Category Name', 'Customer Segment','Customer State', 'Store Country', 'Department Name (Store)','Store City', 'Market', 'Order Region','Order Country', 'Shipping Mode']#'Order City','Order State'\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "encoder_df = df[dummy_columns].apply(le.fit_transform)\n",
    "\n",
    "data_class = df\n",
    "data_class[dummy_columns]=encoder_df\n",
    "#data_class = data_class.drop(['Product Name','Order State','Store City','Order City','Customer Id','Order date (DateOrders)'],axis =1)\n",
    "\n",
    "#get class for profit margin\n",
    "#profit margin categorial name: 0-loss,1-low,2-medium,3-high\n",
    "data_class['profit_cat']='loss'\n",
    "pos_profit = data_class.loc[data_class['Order Item Profit Ratio']>=0]['Order Item Profit Ratio']\n",
    "pos_profit_class = pd.qcut(pos_profit, 3, labels=[\"low\", \"medium\", \"high\"])\n",
    "# pos_profit_class = pd.qcut(pos_profit, 2, labels=[\"low\", \"high\"])\n",
    "data_class.loc[data_class['Order Item Profit Ratio']>=0,'profit_cat']=pos_profit_class\n",
    "\n",
    "#binary \n",
    "data_class['loss']=1\n",
    "data_class.loc[data_class['Order Item Profit Ratio']>=0,'loss']=0\n",
    "\n",
    "data_class['high_profit'] = 0\n",
    "cut_quantile = 0.9\n",
    "q_cut = float(data_class['Order Item Profit Ratio'].quantile([cut_quantile]))\n",
    "data_class.loc[df['Order Item Profit Ratio']>=q_cut,'high_profit']=1\n",
    "\n",
    "data_class['class']=1\n",
    "data_class.loc[df['Order Item Profit Ratio']>=q_cut,'class']=2\n",
    "data_class.loc[(df['Order Item Profit Ratio']<q_cut)&(df['Order Item Profit Ratio']>=0),'class']=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4054d29",
   "metadata": {},
   "source": [
    "# High profit (90 quantile) Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94c63576",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_class.drop(['Order Item Profit Ratio','profit_cat','loss','high_profit','class'],axis =1)\n",
    "y = data_class['high_profit']\n",
    "X = StandardScaler().fit_transform(X)\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc7275",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('RF, accuracy:\\n ',accuracy_score(y_test, y_pred))\n",
    "print('RF, c_m: \\n',confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cd5091",
   "metadata": {},
   "source": [
    "# High profit (90 quantile) 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f512fb71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, accuracy:\n",
      "  0.782422293676313\n",
      "RF, c_m: \n",
      " [[3037  224  123]\n",
      " [ 782 2290  415]\n",
      " [ 509  180 2703]]\n"
     ]
    }
   ],
   "source": [
    "X = data_class.drop(['Order Item Profit Ratio','profit_cat','loss','high_profit','class'],axis =1)\n",
    "X_cols = list(X.columns)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = data_class['class']\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.50)\n",
    "# X_train = StandardScaler().fit_transform(X_train)\n",
    "# X_test = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('RF, accuracy:\\n ',accuracy_score(y_test, y_pred))\n",
    "print('RF, c_m: \\n',confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda5d0e",
   "metadata": {},
   "source": [
    "# Discount Rate Optimization and Calculate Expected Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_class.drop(['class','Order Item Profit Ratio','profit_cat','loss','high_profit'], axis=1)#.to_numpy()\n",
    "X1 = X.to_numpy()\n",
    "X = pd.DataFrame(StandardScaler().fit_transform(X),index =X.index, columns = X.columns)\n",
    "discounts = X['Order Item Discount Rate'].unique()\n",
    "\n",
    "best_discount_list = list()\n",
    "optimal_class_list = list()\n",
    "original_class_list = list()\n",
    "intitial_discount_list =list()\n",
    "\n",
    "#number of samples\n",
    "sample_size = 10000\n",
    "count = 0\n",
    "# for i in range(len(X_test)):\n",
    "for i in range(sample_size):\n",
    "    count+=1\n",
    "    print(count)\n",
    "    sample = X.iloc[i]\n",
    "    initial_discount = sample['Order Item Discount Rate']\n",
    "    intitial_discount_list.append(initial_discount)\n",
    "    sample = sample.values.reshape(1, -1)\n",
    "#     sample = StandardScaler().fit_transform(sample)\n",
    "    y_pred = clf.predict(sample)\n",
    "    initial_class = int(y_pred)\n",
    "    original_class_list.append(initial_class)\n",
    "    y_pred_dict= dict()\n",
    "    if initial_class == 2:\n",
    "        best_discount_list.append(initial_discount)\n",
    "        optimal_class_list.append(initial_class)\n",
    "        continue\n",
    "    else:\n",
    "        for discount in discounts:\n",
    "            sample = X.iloc[i]\n",
    "            sample['Order Item Discount Rate'] = discount\n",
    "            sample = sample.values.reshape(1, -1)\n",
    "#             sample = StandardScaler().fit_transform(sample)\n",
    "            y_pred = clf.predict(sample)\n",
    "            y_pred_dict[discount]=int(y_pred) \n",
    "        best_discount = max(y_pred_dict, key=y_pred_dict.get)\n",
    "        pred_class = max(y_pred_dict.values())\n",
    "        if pred_class > initial_class:\n",
    "            best_discount_list.append(best_discount)\n",
    "            print('change',best_discount)\n",
    "            optimal_class_list.append(pred_class)\n",
    "        else:\n",
    "            best_discount_list.append(initial_discount)\n",
    "            optimal_class_list.append(initial_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_df = data_class.iloc[0:sample_size]\n",
    "optimal_df ['Optimal Discount'] = best_discount_list\n",
    "\n",
    "#     optimal_df = scaler.inverse_transform(optimal_df)\n",
    "#     optimal_df =  pd.DataFrame(optimal_df,columns = X_cols)\n",
    "\n",
    "\n",
    "optimal_df ['Optimal Class'] = optimal_class_list\n",
    "optimal_df ['Initial Class'] = original_class_list\n",
    "optimal_df ['Initial Discount'] = intitial_discount_list\n",
    "optimal_df[['Order Item Profit Ratio','Initial Discount','Optimal Discount','Initial Class','Optimal Class','Order Item Total']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac87f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "change = optimal_df.loc[optimal_df['Initial Class'] != optimal_df['Optimal Class']]\n",
    "change = change[['Order Item Profit Ratio','Initial Discount','Optimal Discount','Initial Class','Optimal Class','Order Item Total']]\n",
    "change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "fca18411",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_profit = sum(change['Order Item Profit Ratio']*change['Order Item Total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a4dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_profit = sum(change['Order Item Profit Ratio']*change['Order Item Total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "00d61c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_2 = len(change['Optimal Class'] ==2)\n",
    "sales_2 = change.loc[change['Optimal Class'] ==2]['Order Item Total'].sum()\n",
    "class_1 = len(change['Optimal Class'] ==1)\n",
    "sales_1 = change.loc[change['Optimal Class'] ==1]['Order Item Total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "bb14360e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43291.15052831"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "690bf955",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_profit = (0.876 * 0.482 + 0.035 * 0.257 + 0.088 * -0.652) * sales_2 + (0.109 * 0.482 + 0.723 * 0.257 +0.168 * -0.652)*sales_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "cacfe2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26634.053342411935"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "345aae02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13441.332760141302"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "ee30837e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13192.720582270633"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_profit - original_profit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5419c7cb",
   "metadata": {},
   "source": [
    "# Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2743e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "rfe = RFECV(estimator=RandomForestClassifier())\n",
    "model = RandomForestClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd138424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "X = data_class.drop(['Order Item Profit Ratio','profit_cat','loss','high_profit'],axis =1)\n",
    "y = data_class['high_profit']\n",
    "X = StandardScaler().fit_transform(X)\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.50)\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
    "sel.fit(X_train, y_train)\n",
    "\n",
    "X_important_train = sel.transform(X_train)\n",
    "X_important_test = sel.transform(X_test)\n",
    "\n",
    "clf_important = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "clf_important.fit(X_important_train, y_train)\n",
    "y_pred = clf_important.predict(X_important_test)\n",
    "print('RF, accuracy:\\n ',accuracy_score(y_test, y_pred))\n",
    "print('RF, c_m: \\n',confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189733ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
